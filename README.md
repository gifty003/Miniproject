## Cloud-Enhanced Automatic Public Street Light System for Sustainable Urban Illumination
To enhance conventional maintenance techniques, the project intends to create a smart street light system with automatic and real-time monitoring in order to identify problems.

## About
<!--Detailed Description about the project-->
Street lighting plays a critical role in public infrastructure in contemporary urban areas, assuring safety, improving road user visibility, and improving general quality of life. Despite their significance, traditional street lighting systems have a number of operational issues because of ineffective maintenance procedures and a deficiency of real-time monitoring tools. Frequently, these systems depend on manual examinations or open-access reports to detect problems like burned-out lightbulbs, malfunctioning wiring, or power disruptions.

The lack of integration between street lighting and smart city initiatives further limits the potential for optimizing urban infrastructure.A more intelligent system would allow for centralized control, enabling city administrators to monitor and manage streetlights remotely, diagnose problems, and deploy maintenance teams more effectively.

## Features
<!--List the features of the project as shown below-->
- Advanced Deep learning algorithms.
- High adaptability to dynamic environments and terrains.
- Real-time data processing with integrated sensors like LDR.
- Utilizes Blynk applcation for Alloting.
- Scalable design with modular architecture for future enhancements.
- Multimodal integration of data inputs for better environmental awareness.

## Requirements
<!--List the requirements of the project as shown below-->
* Operating System: Requires a 64-bit OS (Windows 10, Ubuntu 20.04) for compatibility with simulation and real-time processing frameworks.
* Development Environment: Python 3.8 or later, suitable for deep learning.
* Deep Learning Frameworks: TensorFlow for policy optimization and OpenAI Gym for simulation.
* Simulation Tools: PyBullet, Gazebo, and MATLAB Simulink for real-world modeling.
* Microcontroller: Arduino Nano for controlling sensors and actuators.
* Hardware Components:
  * Sensors: LDR for Light tracking.
  * Applications: Blynk app for fault detection.
  * Bulbs: 100 watts bulbs.
* IDE: Arduino IDE and Visual Studio Code for debugging and deployment.
* Version Control: Git for collaborative development.
* Additional Dependencies: Includes libraries such as scikit-learn, OpenCV, and stable-baselines3 for deep learning.

## System Architecture
<!--Embed the system architecture diagram as shown below-->

![Screenshot 2024-12-19 000726](https://github.com/user-attachments/assets/a4991f16-1356-4368-bd0d-e70fc21e78f9)




## Output

<!--Embed the Output picture at respective places as shown below as shown below-->
#### Output1 - real time output

![mini pro](https://github.com/user-attachments/assets/015bacd5-0e3b-4079-ab1f-c6c4e4afee5b)

Detection Accuracy: 96.2%



## Results and Impact
<!--Give the results and impact as shown below-->
The Sign Language Detection System enhances accessibility for individuals with hearing and speech impairments, providing a valuable tool for inclusive communication. The project's integration of computer vision and deep learning showcases its potential for intuitive and interactive human-computer interaction.

This project serves as a foundation for future developments in assistive technologies and contributes to creating a more inclusive and accessible digital environment.

## Articles published / References
1. N. S. Gupta, S. K. Rout, S. Barik, R. R. Kalangi, and B. Swampa, “Enhancing Heart Disease Prediction Accuracy Through Hybrid Machine Learning Methods ”, EAI Endorsed Trans IoT, vol. 10, Mar. 2024.
2. A. A. BIN ZAINUDDIN, “Enhancing IoT Security: A Synergy of Machine Learning, Artificial Intelligence, and Blockchain”, Data Science Insights, vol. 2, no. 1, Feb. 2024.




